{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Stealing Attack - Assignment 2\n",
    "\n",
    "**Team Number**: 19 \n",
    "**Task**: Implement a model stealing attack against B4B-protected encoder while minimizing L2 distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxruntime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mort\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Set device\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnxruntime'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import requests\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import onnxruntime as ort\n",
    "import time\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"mps\") # if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. API Connection Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication token for the target API\n",
    "TOKEN = \"50407833\" \n",
    "PORT = None\n",
    "SEED = None\n",
    "\n",
    "def launch_api():\n",
    "    \"\"\"Initialize connection to the target API and get session details\"\"\"\n",
    "    global PORT, SEED\n",
    "    response = requests.get(\n",
    "        \"http://34.122.51.94:9090/stealing_launch\",\n",
    "        headers={\"token\": TOKEN}\n",
    "    )\n",
    "    answer = response.json()\n",
    "    if 'detail' in answer:\n",
    "        raise Exception(f\"API launch failed: {answer['detail']}\")\n",
    "    SEED = str(answer['seed'])\n",
    "    PORT = str(answer['port'])\n",
    "    print(f\"API launched. Seed: {SEED}, Port: {PORT}\")\n",
    "    return SEED, PORT\n",
    "\n",
    "def query_api(images, retries=3, delay=60):\n",
    "    \"\"\"Send image batch to API and get embedding representations\n",
    "    \n",
    "    Handles rate limiting with exponential backoff retry mechanism\n",
    "    \"\"\"\n",
    "    endpoint = \"/query\"\n",
    "    url = f\"http://34.122.51.94:{PORT}\" + endpoint\n",
    "    image_data = []\n",
    "    \n",
    "    # Convert images to base64 format for API request\n",
    "    for img in images:\n",
    "        img = transforms.ToPILImage()(img.cpu())\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr.seek(0)\n",
    "        img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "        image_data.append(img_base64)\n",
    "    \n",
    "    payload = json.dumps(image_data)\n",
    "    response = requests.get(url, files={\"file\": payload}, headers={\"token\": TOKEN})\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"representations\"]\n",
    "    elif response.status_code == 429:\n",
    "        if retries > 0:\n",
    "            print(\"Rate limited. Retrying after delay...\")\n",
    "            time.sleep(delay)\n",
    "            return query_api(images, retries - 1, delay * 2)\n",
    "        else:\n",
    "            raise Exception(\"Too many retries. Still getting rate-limited.\")\n",
    "    else:\n",
    "        raise Exception(f\"Query failed. Code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Coverage Tracking System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoverageTracker:\n",
    "    \"\"\"Tracks our coverage of the target model's embedding space\n",
    "    \n",
    "    Uses a bucketing approach to estimate how much of the embedding space\n",
    "    we've explored. This helps avoid triggering B4B protection.\n",
    "    \"\"\"\n",
    "    def __init__(self, bucket_size=0.15, max_buckets=4096):\n",
    "        self.bucket_map = defaultdict(bool)\n",
    "        self.bucket_size = bucket_size\n",
    "        self.max_buckets = max_buckets\n",
    "        self.query_count = 0\n",
    "        \n",
    "    def _hash_embedding(self, emb):\n",
    "        \"\"\"Convert embedding vector to discrete bucket coordinates\n",
    "        \n",
    "        Uses just the first 5 dimensions for efficiency\n",
    "        \"\"\"\n",
    "        emb = np.array(emb)\n",
    "        return tuple(np.floor(emb[:5] / self.bucket_size))\n",
    "        \n",
    "    def update_coverage(self, embeddings):\n",
    "        \"\"\"Process new embeddings and update coverage statistics\"\"\"\n",
    "        for emb in embeddings:\n",
    "            self.bucket_map[self._hash_embedding(emb)] = True\n",
    "        self.query_count += len(embeddings)\n",
    "        \n",
    "    def get_coverage(self):\n",
    "        \"\"\"Calculate percentage of embedding space covered\"\"\"\n",
    "        return len(self.bucket_map) / self.max_buckets\n",
    "    \n",
    "    def is_safe(self, sample_size=1000):\n",
    "        \"\"\"Check if adding more samples is likely to stay under B4B thresholds\"\"\"\n",
    "        current = len(self.bucket_map)\n",
    "        projected = current + (sample_size * 0.1)\n",
    "        return projected / self.max_buckets < 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskDataset(Dataset):\n",
    "    \"\"\"Dataset class for the image collection used in model stealing\n",
    "    \n",
    "    Handles image loading, preprocessing and transformations\n",
    "    \"\"\"\n",
    "    def __init__(self, transform=None):\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.CenterCrop(32),\n",
    "            transforms.Lambda(self._ensure_rgb),\n",
    "            transforms.ToTensor(),\n",
    "            # Use dataset-specific mean and std for normalization\n",
    "            transforms.Normalize((0.2980, 0.2962, 0.2987), (0.2886, 0.2875, 0.2889))\n",
    "        ])\n",
    "\n",
    "    def _ensure_rgb(self, img):\n",
    "        \"\"\"Convert grayscale images to RGB if needed\"\"\"\n",
    "        if img.mode != 'RGB':\n",
    "            return img.convert('RGB')\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "def load_stealing_dataset(data_path=\"ModelStealingPub.pt\"):\n",
    "    \"\"\"Load the dataset of candidate images for stealing\"\"\"\n",
    "    original_data = torch.load(data_path, map_location=\"cpu\", weights_only=False)\n",
    "    dataset = TaskDataset()\n",
    "    dataset.ids = original_data.ids\n",
    "    dataset.imgs = original_data.imgs\n",
    "    dataset.labels = original_data.labels\n",
    "    return dataset\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function to handle (image, embedding) pairs\"\"\"\n",
    "    images = torch.stack([item[0] for item in batch])\n",
    "    targets = torch.stack([item[1] for item in batch])\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStealer(nn.Module):\n",
    "    \"\"\"Neural network model designed to replicate the target encoder\n",
    "    \n",
    "    Uses convolutional layers for feature extraction followed by\n",
    "    fully connected layers to generate embeddings\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dim=1024):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature extraction layers - 3 conv blocks with batch norm\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        \n",
    "        # Embedding generation layers\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.embedding(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs=5):\n",
    "    \"\"\"Train the model using collected image-embedding pairs\n",
    "    \n",
    "    Uses MSE loss to minimize L2 distance between predicted\n",
    "    and target embeddings\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for images, targets in tqdm(train_loader):\n",
    "            images = images.to(device)\n",
    "            targets = targets.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Handle any shape mismatches (shouldn't happen with proper setup)\n",
    "            if outputs.shape != targets.shape:\n",
    "                print(f\"Shape mismatch! Output: {outputs.shape}, Target: {targets.shape}\")\n",
    "                targets = targets.view_as(outputs)\n",
    "                \n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Main Execution Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API launched. Seed: 28160397, Port: 9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('28160397', '9944')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize API connection - this gets our unique PORT and SEED values\n",
    "# def main():\n",
    "    # Initialize API connection\n",
    "launch_api()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 13000 images\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_stealing_dataset()\n",
    "print(f\"Loaded dataset with {len(dataset)} images\")\n",
    "\n",
    "# Initialize our coverage tracking system\n",
    "tracker = CoverageTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1: Initial low-diversity queries\n",
      "Queries: 1000, Coverage: 0.32%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 2000, Coverage: 0.39%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 3000, Coverage: 0.39%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 4000, Coverage: 0.39%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 5000, Coverage: 0.42%\n"
     ]
    }
   ],
   "source": [
    "# Phase 1: Initial queries (low diversity)\n",
    "# This establishes our baseline data for later targeted queries\n",
    "print(\"Phase 1: Initial low-diversity queries\")\n",
    "train_data = []\n",
    "\n",
    "for _ in range(5):  # 5 queries x 1000 images = 5000 initial samples\n",
    "    # Randomly select 1000 images from the dataset\n",
    "    batch_indices = np.random.choice(len(dataset), 1000, replace=False)\n",
    "    batch_images = [dataset[i] for i in batch_indices]\n",
    "    batch_embs = query_api(batch_images)\n",
    "\n",
    "    # Store images and their corresponding embeddings\n",
    "    for img, emb in zip(batch_images, batch_embs):\n",
    "        train_data.append((img, torch.tensor(emb).float()))\n",
    "\n",
    "    tracker.update_coverage(batch_embs)\n",
    "    print(f\"Queries: {tracker.query_count}, Coverage: {tracker.get_coverage():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 2: Strategic coverage expansion\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 6000, Coverage: 0.46%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 7000, Coverage: 0.49%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 8000, Coverage: 0.49%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 9000, Coverage: 0.49%\n",
      "Rate limited. Retrying after delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:46<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:46<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:46<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0032\n",
      "Queries: 10000, Coverage: 0.51%\n",
      "Queries: 11000, Coverage: 0.54%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 12000, Coverage: 0.54%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 13000, Coverage: 0.54%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 14000, Coverage: 0.54%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 15000, Coverage: 0.56%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 16000, Coverage: 0.56%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 17000, Coverage: 0.56%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 18000, Coverage: 0.56%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 19000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:34<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:34<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:37<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0027\n",
      "Queries: 20000, Coverage: 0.59%\n",
      "Queries: 21000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 22000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 23000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 24000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 25000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 26000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 27000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 28000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 29000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [02:26<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [02:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [02:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0022\n",
      "Queries: 30000, Coverage: 0.59%\n",
      "Queries: 31000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 32000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 33000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 34000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 35000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 36000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 37000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 38000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 39000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [03:14<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [03:17<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [03:14<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0020\n",
      "Queries: 40000, Coverage: 0.59%\n",
      "Queries: 41000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 42000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 43000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 44000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 45000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 46000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 47000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 48000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 49000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [04:21<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [04:48<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [04:02<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0019\n",
      "Queries: 50000, Coverage: 0.59%\n",
      "Queries: 51000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 52000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 53000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 54000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 55000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 56000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 57000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 58000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 59000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [04:43<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [04:41<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [04:42<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0018\n",
      "Queries: 60000, Coverage: 0.59%\n",
      "Queries: 61000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 62000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 63000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 64000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 65000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 66000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 67000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 68000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 69000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274/274 [05:25<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274/274 [05:22<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274/274 [05:24<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0017\n",
      "Queries: 70000, Coverage: 0.59%\n",
      "Queries: 71000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 72000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 73000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 74000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 75000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 76000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 77000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 78000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 79000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [06:18<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [06:14<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [06:20<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0016\n",
      "Queries: 80000, Coverage: 0.59%\n",
      "Queries: 81000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 82000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 83000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 84000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 85000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 86000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 87000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 88000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 89000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [07:02<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [07:02<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [07:04<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0016\n",
      "Queries: 90000, Coverage: 0.59%\n",
      "Queries: 91000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 92000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 93000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 94000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 95000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 96000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 97000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 98000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n",
      "Queries: 99000, Coverage: 0.59%\n",
      "Rate limited. Retrying after delay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [08:03<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [08:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [08:00<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0015\n",
      "Queries: 100000, Coverage: 0.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Phase 2: Strategic expansion\n",
    "# This is where we use most of our query budget to maximize coverage\n",
    "print(\"\\nPhase 2: Strategic coverage expansion\")\n",
    "\n",
    "while tracker.query_count < 100000 and tracker.get_coverage() < 0.3:\n",
    "    # Get exactly 1000 samples per query (API requirement)\n",
    "    batch_images = [dataset[i] for i in np.random.choice(len(dataset), 1000)]\n",
    "    batch_embs = query_api(batch_images)\n",
    "\n",
    "    # Update tracking and training data\n",
    "    for img, emb in zip(batch_images, batch_embs):\n",
    "        train_data.append((img, torch.tensor(emb).float()))\n",
    "\n",
    "    tracker.update_coverage(batch_embs)\n",
    "\n",
    "    # Periodic training every 10,000 samples to check progress\n",
    "    if len(train_data) % 10000 == 0:\n",
    "        loader = DataLoader(train_data, batch_size=256, shuffle=True, collate_fn=collate_fn)\n",
    "        model = EncoderStealer(output_dim=1024).to(device)\n",
    "        train_model(model, loader, epochs=3)\n",
    "\n",
    "    print(f\"Queries: {tracker.query_count}, Coverage: {tracker.get_coverage():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 100000 samples from 100000 queries\n",
      "Proceeding to final training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [07:57<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [07:58<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [07:58<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [07:59<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [08:09<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0013\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "ONNX validation failed: Input name should be 'x', got input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m, in \u001b[0;36mvalidate_onnx\u001b[1;34m(model_path)\u001b[0m\n\u001b[0;32m      5\u001b[0m input_name \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mget_inputs()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput name should be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m test_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Input name should be 'x', got input",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 21\u001b[0m\n\u001b[0;32m     11\u001b[0m     dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m     torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mexport(\n\u001b[0;32m     13\u001b[0m         model,\n\u001b[0;32m     14\u001b[0m         dummy_input,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m         dynamic_axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m}, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m}}\n\u001b[0;32m     19\u001b[0m     )\n\u001b[1;32m---> 21\u001b[0m     validate_onnx(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstolen_model.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m     submit_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstolen_model.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[16], line 14\u001b[0m, in \u001b[0;36mvalidate_onnx\u001b[1;34m(model_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONNX validation passed! Model meets submission requirements\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONNX validation failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: ONNX validation failed: Input name should be 'x', got input"
     ]
    }
   ],
   "source": [
    "# Attempt to move forward with the data we've collected\n",
    "# If something went wrong earlier, this will catch and report the error\n",
    "try:\n",
    "    print(f\"Collected {len(train_data)} samples from {tracker.query_count} queries\")\n",
    "    print(\"Proceeding to final training...\")\n",
    "    \n",
    "    final_loader = DataLoader(train_data, batch_size=256, shuffle=True, collate_fn=collate_fn)\n",
    "    model = EncoderStealer(output_dim=1024).to(device)\n",
    "    train_model(model, final_loader, epochs=5)\n",
    "    \n",
    "    # Export to ONNX for submission\n",
    "    dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        \"stolen_model.onnx\",\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    "    )\n",
    "    \n",
    "    validate_onnx(\"stolen_model.onnx\")\n",
    "    submit_model(\"stolen_model.onnx\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"Error: No training data collected yet. Run main() first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model training with all collected data\n",
    "print(\"\\nFinal training\")\n",
    "final_loader = DataLoader(train_data, batch_size=256, shuffle=True, collate_fn=collate_fn)\n",
    "model = EncoderStealer(output_dim=1024).to(device)\n",
    "train_model(model, final_loader, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_onnx(model_path):\n",
    "    \"\"\"Verify that our ONNX model meets submission requirements\n",
    "    \n",
    "    Checks for correct input name and output shape\n",
    "    \"\"\"\n",
    "    try:\n",
    "        session = ort.InferenceSession(model_path)\n",
    "        # Check input name matches 'x'\n",
    "        input_name = session.get_inputs()[0].name\n",
    "        assert input_name == \"x\", f\"Input name should be 'x', got {input_name}\"\n",
    "        \n",
    "        test_input = np.random.randn(1, 3, 32, 32).astype(np.float32)\n",
    "        output = session.run(None, {\"x\": test_input})[0]  # Note using \"x\" here\n",
    "        \n",
    "        assert output.shape == (1, 1024)\n",
    "        print(\"ONNX validation passed! Model meets submission requirements\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"ONNX validation failed: {str(e)}\")\n",
    "        \n",
    "def submit_model(model_path):\n",
    "    \"\"\"Submit the stolen model to the evaluation server\"\"\"\n",
    "    url = \"http://34.122.51.94:9090/stealing\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        files = {\"file\": f}\n",
    "        headers = {\"token\": TOKEN, \"seed\": SEED}\n",
    "        response = requests.post(url, files=files, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"Submission successful!\")\n",
    "        print(response.json())\n",
    "    else:\n",
    "        print(f\"Submission failed: {response.status_code}\")\n",
    "        print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing for submission...\n",
      "Model test - Input shape: torch.Size([1, 3, 32, 32]), Output shape: torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "# Prepare for final submission\n",
    "print(\"\\nPreparing for submission...\")\n",
    "\n",
    "# 1. Verify model output shape\n",
    "test_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "with torch.no_grad():\n",
    "    test_output = model(test_input)\n",
    "print(f\"Model test - Input shape: {test_input.shape}, Output shape: {test_output.shape}\")\n",
    "\n",
    "# 2. Export with correct input name (must be \"x\" for server)\n",
    "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"stolen_model.onnx\",\n",
    "    input_names=[\"x\"],  # Must be \"x\" to match server expectations\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\n",
    "        'x': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    },\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX validation passed! Model meets submission requirements\n"
     ]
    }
   ],
   "source": [
    "# Validate ONNX\n",
    "validate_onnx(\"stolen_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit model\n",
    "submit_model(\"stolen_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Submission Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run the Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
